{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEH6kUdHIB7/WxXDpatSHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nouran-Khallaf/why-tough/blob/main/Classification_interpertability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Captum --- integreted graidiants\n",
        "To understand how each word contributes to the classification, we can use an interpretability technique like Integrated Gradients. The Captum library provides tools to calculate such attributions."
      ],
      "metadata": {
        "id": "Y6WXOUXLIpSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Captum\n",
        "!pip install captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbfn96I3_dJd",
        "outputId": "560c69eb-b03e-4de6-cb67-02da68eac7a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from captum) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->captum) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->captum) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This imports the necessary libraries and modules required for the notebook.\n",
        "\n",
        "- **`pandas`**: For data manipulation and analysis.  \n",
        "- **`torch`**: For PyTorch functionality, including tensors and GPU support.  \n",
        "- **`transformers`**: Provides pre-trained transformer models and tokenizers for NLP tasks.  \n",
        "  - `AutoModelForSequenceClassification`, `AutoTokenizer`: Automatically load pre-trained models and tokenizers.\n",
        "  - `BertForSequenceClassification`: Specifically for using BERT for classification tasks.  \n",
        "- **`captum.attr`**: For explainable AI, including `LayerIntegratedGradients` and `LayerConductance` to compute attributions, and `visualization` to visualize results.  \n",
        "- **`IPython.display`**: For rendering rich outputs like HTML or interactive visualizations in Jupyter notebooks.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NQM60tEoJheC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BertForSequenceClassification,BertTokenizer\n",
        "from captum.attr import  LayerIntegratedGradients, visualization as viz, LayerConductance\n",
        "from IPython.display import display, HTML\n"
      ],
      "metadata": {
        "id": "5X908Cxdq_cz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description:  \n",
        "This setup prepares the tokenizer and model for the task, Here we load our Pre-trained Classifier model\n",
        "but you can use anyother model. uncomment if you wish to use your own model\n",
        "\n",
        "\n",
        "1. **Tokenizer Initialization**:  \n",
        "   - Loads a pre-trained tokenizer (`BertTokenizer`) from the `bert-base-multilingual-cased` model.\n",
        "\n",
        "2. **Model Initialization**:  \n",
        "   - Loads the pre-trained `BertForSequenceClassification` model with `bert-base-multilingual-cased` configuration.\n",
        "   - Configures the model for binary classification (`num_labels=2`).\n",
        "\n",
        "3. **Model Weights Loading**:  \n",
        "   - Loads the pre-trained weights for the model from a file named `'Basic_original_SpaCy_model_bert.pth'`.  \n",
        "\n"
      ],
      "metadata": {
        "id": "uIxOaeMyKfUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer and model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "#model.load_state_dict(torch.load('Basic_original_SpaCy_model_bert.pth', map_location=device))\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoplvKAQEIo6",
        "outputId": "3fd6c8ea-239a-4d43-9801-2889dba3af05"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `XAI` (Explainable AI) class is designed to provide explanations for predictions made by a transformer-based classification model. It combines model interpretation techniques with visualization tools to analyse and understand the contribution of individual tokens to the model's predictions.\n",
        "#### Key Components:\n",
        "\n",
        "1. **Initialization (`__init__`)**:\n",
        "   - Stores input text, label, tokenizer, model, and computation device.\n",
        "   - Initializes placeholders for input IDs and reference input IDs (used for attributions).\n",
        "\n",
        "2. **Input Construction (`construct_input_ref`)**:\n",
        "   - Creates tokenized inputs and reference (baseline) inputs for the model.\n",
        "   - Reference inputs are padded versions of the input text, used as a baseline in attribution methods.\n",
        "\n",
        "3. **Custom Forward Pass (`custom_forward`)**:\n",
        "   - Defines a forward function for the model that outputs softmax probabilities for classification.\n",
        "\n",
        "4. **Attribution Computation (`compute_attributions`)**:\n",
        "   - Computes token-level attributions using Layer Integrated Gradients (LIG) from Captum.\n",
        "   - Normalizes attributions for consistency and returns them alongside the input tokens.\n",
        "\n",
        "5. **Prediction Probabilities (`predict_probabilities`)**:\n",
        "   - Computes the model's classification probabilities for the input text.\n",
        "\n",
        "6. **Top-K Attributed Tokens (`get_topk_attributed_tokens`)**:\n",
        "   - Identifies the top \\(k\\) tokens with the highest attribution scores.\n",
        "   - Returns a DataFrame containing the tokens, their indices, and attribution values.\n",
        "\n",
        "7. **HTML Generation (`generate_html`)**:\n",
        "   - Creates an interactive HTML visualization to display:\n",
        "     - The model's prediction probabilities.\n",
        "     - Input text with highlighted attributions (color-coded for positive/negative contributions).\n",
        "\n",
        "---\n",
        "\n",
        "#### Purpose:\n",
        "This class enables detailed analysis of how each word in the input text influences the model's prediction. It provides both numerical insights (via `get_topk_attributed_tokens`) and visual representations (via `generate_html`). This makes it a powerful tool for debugging, understanding model behavior, and improving model transparency in NLP tasks."
      ],
      "metadata": {
        "id": "xHc4as5GLVam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XAI:\n",
        "    def __init__(self, text_, label_, tokenizer_, model_, device_):\n",
        "        \"\"\"\n",
        "        Initialize the XAI class with text, label, tokenizer, model, and computation device.\n",
        "        \"\"\"\n",
        "        self.text = text_  # Input text to analyze\n",
        "        self.label = label_  # True label or target label\n",
        "        self.tokenizer = tokenizer_  # Tokenizer for text preprocessing\n",
        "        self.model = model_  # Model to explain\n",
        "        self.device = device_  # Computation device (CPU or GPU)\n",
        "        self.input_ids = None  # Tokenized input IDs\n",
        "        self.ref_input_ids = None  # Reference (baseline) input IDs\n",
        "\n",
        "    def construct_input_ref(self):\n",
        "        \"\"\"\n",
        "        Create tokenized input and reference (baseline) input for the model.\n",
        "        The reference input is a padded version of the text, used for attributions.\n",
        "        \"\"\"\n",
        "        # Tokenize the input text (excluding special tokens like [CLS] and [SEP])\n",
        "        text_ids = self.tokenizer.encode(self.text, add_special_tokens=False)\n",
        "\n",
        "        # Create input with special tokens\n",
        "        input_ids = [self.tokenizer.cls_token_id] + text_ids + [self.tokenizer.sep_token_id]\n",
        "\n",
        "        # Create reference (baseline) input with padding tokens\n",
        "        ref_input_ids = [self.tokenizer.cls_token_id] + [self.tokenizer.pad_token_id] * len(text_ids) + [self.tokenizer.sep_token_id]\n",
        "\n",
        "        # Convert to tensors and move to the specified device\n",
        "        self.input_ids = torch.tensor([input_ids], device=self.device)\n",
        "        self.ref_input_ids = torch.tensor([ref_input_ids], device=self.device)\n",
        "\n",
        "        return self.input_ids, self.ref_input_ids\n",
        "\n",
        "    def custom_forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Custom forward function to compute softmax probabilities for classification.\n",
        "        \"\"\"\n",
        "        # Pass the input through the model and apply softmax to get probabilities\n",
        "        return torch.softmax(self.model(inputs)[0], dim=1)[0]\n",
        "\n",
        "    def compute_attributions(self):\n",
        "        \"\"\"\n",
        "        Compute token-level attributions using Layer Integrated Gradients (LIG).\n",
        "        Returns normalized attributions and corresponding tokens.\n",
        "        \"\"\"\n",
        "        # Generate tokenized input and reference input\n",
        "        self.input_ids, self.ref_input_ids = self.construct_input_ref()\n",
        "        # Convert input IDs back to tokens\n",
        "        self.tokens = self.tokenizer.convert_ids_to_tokens(self.input_ids[0])\n",
        "\n",
        "        # Initialize Layer Integrated Gradients (LIG) with the model's embeddings\n",
        "        lig = LayerIntegratedGradients(self.custom_forward, self.model.bert.embeddings)\n",
        "\n",
        "        # Compute attributions using LIG\n",
        "        attributions, delta = lig.attribute(\n",
        "            inputs=self.input_ids,  # Tokenized input\n",
        "            baselines=self.ref_input_ids,  # Baseline input\n",
        "            n_steps=500,  # Number of steps along the path\n",
        "            internal_batch_size=3,  # Batch size for internal computation\n",
        "            return_convergence_delta=True  # Return convergence delta\n",
        "        )\n",
        "\n",
        "        # Sum attributions across the embedding dimensions\n",
        "        attributions = attributions.sum(dim=-1).squeeze()\n",
        "        # Normalize attributions for consistency\n",
        "        normalized_attributions = attributions / torch.norm(attributions)\n",
        "\n",
        "        return normalized_attributions, self.tokens\n",
        "\n",
        "    def predict_probabilities(self):\n",
        "        \"\"\"\n",
        "        Predict the probabilities for the input text using the model.\n",
        "        \"\"\"\n",
        "        # Compute probabilities using the custom forward function\n",
        "        outputs = self.custom_forward(self.input_ids)\n",
        "        return outputs.tolist()\n",
        "\n",
        "    def get_topk_attributed_tokens(self, attrs, k=5):\n",
        "        \"\"\"\n",
        "        Identify the top-k tokens with the highest attribution scores.\n",
        "        Returns a DataFrame with tokens, their indices, and attribution values.\n",
        "        \"\"\"\n",
        "        # Ensure attributions are on the CPU\n",
        "        attrs = attrs.cpu()\n",
        "        # Get the top-k attribution values and their indices\n",
        "        values, indices = torch.topk(attrs, k)\n",
        "        # Map indices to tokens\n",
        "        top_tokens = [self.tokens[idx] for idx in indices]\n",
        "        # Create and return a DataFrame with results\n",
        "        return pd.DataFrame({\n",
        "            'Word': top_tokens,\n",
        "            'Index': indices.cpu().numpy(),\n",
        "            'Attribution': values.cpu().numpy()\n",
        "        })\n",
        "\n",
        "    def generate_html(self, attributions, tokens, probabilities):\n",
        "        \"\"\"\n",
        "        Generate an interactive HTML visualization for:\n",
        "        - Prediction probabilities\n",
        "        - Input text with token-level attributions (color-coded)\n",
        "        \"\"\"\n",
        "        # Create a color-coded visualization of tokens\n",
        "        token_html = \"\"\n",
        "        for token, score in zip(tokens, attributions):\n",
        "            # Determine color intensity based on the attribution score\n",
        "            color = f\"rgba(255, 0, 0, {abs(score)})\" if score < 0 else f\"rgba(0, 0, 255, {abs(score)})\"\n",
        "            token_html += f\"<span style='background-color: {color}; padding: 2px;'>{token} </span>\"\n",
        "\n",
        "        # Generate HTML with prediction probabilities and highlighted tokens\n",
        "        html_content = f\"\"\"\n",
        "        <div style=\"margin-bottom: 20px;\">\n",
        "            <h4>Prediction Probabilities</h4>\n",
        "            <div>\n",
        "                <div>Simple</div>\n",
        "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
        "                    <div style=\"width: {probabilities[0] * 100}%; height: 100%; background-color: blue; border-radius: 5px;\"></div>\n",
        "                </div>\n",
        "                <p>Probability: {probabilities[0]:.2f}</p>\n",
        "\n",
        "                <div>Complex</div>\n",
        "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
        "                    <div style=\"width: {probabilities[1] * 100}%; height: 100%; background-color: orange; border-radius: 5px;\"></div>\n",
        "                </div>\n",
        "                <p>Probability: {probabilities[1]:.2f}</p>\n",
        "            </div>\n",
        "\n",
        "            <h4>Text with Highlighted Words</h4>\n",
        "            <p>{token_html}</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        return html_content\n"
      ],
      "metadata": {
        "id": "1Xni8BXeycgF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each sentence:\n",
        "1. **HTML Visualization**: Displays probabilities and highlighted attributions.\n",
        "   - Encapsulates the analysis process into the `analyze_and_display` function. This improves reusability and clarity.\n",
        "   - Accepts a sentence, label, tokenizer, model, device, and an optional `top_k` parameter for flexibility.\n",
        "2. **Top-K Tokens**: A DataFrame is displayed, showing the tokens with the highest attributions.\n",
        "    - Defaults to displaying as many top tokens as there are words in the sentence. This makes the code adaptable for varying sentence lengths.\n",
        "---\n"
      ],
      "metadata": {
        "id": "CtH4SP52PR4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_and_display(sentence, label, tokenizer, model, device, top_k=None):\n",
        "    \"\"\"\n",
        "    Analyze and display attribution and predictions for a given sentence.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The input sentence to analyze.\n",
        "        label (int): The label associated with the sentence.\n",
        "        tokenizer: The tokenizer for text processing.\n",
        "        model: The classification model.\n",
        "        device: The computation device (CPU or GPU).\n",
        "        top_k (int): The number of top tokens to display. Defaults to the number of words in the sentence.\n",
        "    \"\"\"\n",
        "    # Ensure the model is on the correct device\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize the XAI instance\n",
        "    xai_instance = XAI(\n",
        "        text_=sentence,\n",
        "        label_=label,\n",
        "        tokenizer_=tokenizer,\n",
        "        model_=model,\n",
        "        device_=device\n",
        "    )\n",
        "\n",
        "    # Compute attributions and tokens\n",
        "    attributions, tokens = xai_instance.compute_attributions()\n",
        "\n",
        "    # Predict probabilities\n",
        "    probabilities = xai_instance.predict_probabilities()\n",
        "\n",
        "    # Generate HTML visualization\n",
        "    html_content = xai_instance.generate_html(attributions, tokens, probabilities)\n",
        "    display(HTML(html_content))\n",
        "\n",
        "    # Get top-k attributed tokens\n",
        "    if top_k is None:\n",
        "        top_k = len(sentence.split())\n",
        "    top_tokens_df = xai_instance.get_topk_attributed_tokens(attributions, k=top_k)\n",
        "\n",
        "    # Display the top tokens as a DataFrame\n",
        "    display(top_tokens_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "cQqm2SQP8m9i"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of sentences to analyze\n",
        "sentence = \"Provide financially sustainable care, giving security and stability to people and their carers.\"\n",
        "# Perform analysis for  sentence\n",
        "analyze_and_display(sentence, label=1, tokenizer=tokenizer, model=model, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "DsMJtAB5OfCH",
        "outputId": "cd145fe1-1709-4028-ab17-b3691a3f5965"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"margin-bottom: 20px;\">\n",
              "            <h4>Prediction Probabilities</h4>\n",
              "            <div>\n",
              "                <div>Simple</div>\n",
              "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
              "                    <div style=\"width: 3.793613612651825%; height: 100%; background-color: blue; border-radius: 5px;\"></div>\n",
              "                </div>\n",
              "                <p>Probability: 0.04</p>\n",
              "\n",
              "                <div>Complex</div>\n",
              "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
              "                    <div style=\"width: 96.20638489723206%; height: 100%; background-color: orange; border-radius: 5px;\"></div>\n",
              "                </div>\n",
              "                <p>Probability: 0.96</p>\n",
              "            </div>\n",
              "\n",
              "            <h4>Text with Highlighted Words</h4>\n",
              "            <p><span style='background-color: rgba(0, 0, 255, 0.0); padding: 2px;'>[CLS] </span><span style='background-color: rgba(255, 0, 0, 0.2636757144597424); padding: 2px;'>Pro </span><span style='background-color: rgba(255, 0, 0, 0.16753369268016374); padding: 2px;'>##vide </span><span style='background-color: rgba(255, 0, 0, 0.21322723213999475); padding: 2px;'>financial </span><span style='background-color: rgba(0, 0, 255, 0.1299791406687994); padding: 2px;'>##ly </span><span style='background-color: rgba(0, 0, 255, 0.43758072126753617); padding: 2px;'>sustainable </span><span style='background-color: rgba(255, 0, 0, 0.33388205295110296); padding: 2px;'>care </span><span style='background-color: rgba(0, 0, 255, 0.09549432059850742); padding: 2px;'>, </span><span style='background-color: rgba(255, 0, 0, 0.44329524648023577); padding: 2px;'>giving </span><span style='background-color: rgba(255, 0, 0, 0.13802739701961547); padding: 2px;'>security </span><span style='background-color: rgba(0, 0, 255, 0.17945743636902237); padding: 2px;'>and </span><span style='background-color: rgba(255, 0, 0, 0.40035907290989037); padding: 2px;'>stability </span><span style='background-color: rgba(0, 0, 255, 0.019841068675538944); padding: 2px;'>to </span><span style='background-color: rgba(255, 0, 0, 0.24829294133821417); padding: 2px;'>people </span><span style='background-color: rgba(0, 0, 255, 0.150541387824312); padding: 2px;'>and </span><span style='background-color: rgba(255, 0, 0, 0.11892729090804241); padding: 2px;'>their </span><span style='background-color: rgba(255, 0, 0, 0.1318580710735755); padding: 2px;'>care </span><span style='background-color: rgba(255, 0, 0, 0.058459567697024505); padding: 2px;'>##rs </span><span style='background-color: rgba(255, 0, 0, 0.016301547296331445); padding: 2px;'>. </span><span style='background-color: rgba(0, 0, 255, 0.0); padding: 2px;'>[SEP] </span></p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           Word  Index  Attribution\n",
              "0   sustainable      5     0.437581\n",
              "1           and     10     0.179457\n",
              "2           and     14     0.150541\n",
              "3          ##ly      4     0.129979\n",
              "4             ,      7     0.095494\n",
              "5            to     12     0.019841\n",
              "6         [SEP]     19     0.000000\n",
              "7         [CLS]      0     0.000000\n",
              "8             .     18    -0.016302\n",
              "9          ##rs     17    -0.058460\n",
              "10        their     15    -0.118927\n",
              "11         care     16    -0.131858\n",
              "12     security      9    -0.138027"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc9febe2-2577-4452-b5a9-1f1ea7c6a28f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Index</th>\n",
              "      <th>Attribution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sustainable</td>\n",
              "      <td>5</td>\n",
              "      <td>0.437581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and</td>\n",
              "      <td>10</td>\n",
              "      <td>0.179457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and</td>\n",
              "      <td>14</td>\n",
              "      <td>0.150541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>##ly</td>\n",
              "      <td>4</td>\n",
              "      <td>0.129979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>,</td>\n",
              "      <td>7</td>\n",
              "      <td>0.095494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>to</td>\n",
              "      <td>12</td>\n",
              "      <td>0.019841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[SEP]</td>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>18</td>\n",
              "      <td>-0.016302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>##rs</td>\n",
              "      <td>17</td>\n",
              "      <td>-0.058460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>their</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.118927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>care</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.131858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>security</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.138027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc9febe2-2577-4452-b5a9-1f1ea7c6a28f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc9febe2-2577-4452-b5a9-1f1ea7c6a28f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc9febe2-2577-4452-b5a9-1f1ea7c6a28f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb688bda-d5f6-4e0d-a041-411e96f883c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb688bda-d5f6-4e0d-a041-411e96f883c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb688bda-d5f6-4e0d-a041-411e96f883c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"analyze_and_display(sentence, label=1, tokenizer=tokenizer, model=model, device=device)\",\n  \"rows\": 13,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"care\",\n          \"their\",\n          \"sustainable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          16,\n          17,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Attribution\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15911351010687783,\n        \"min\": -0.13802739701961547,\n        \"max\": 0.43758072126753617,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -0.1318580710735755,\n          -0.11892729090804241,\n          0.43758072126753617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Provide cheap care that helps people and their carers feel safe.\"\n",
        "# Perform analysis for  sentence\n",
        "analyze_and_display(sentence, label=1, tokenizer=tokenizer, model=model, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "b71aJ4qHO29A",
        "outputId": "85588368-c3f0-45a7-dc0a-1254cf8e6704"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div style=\"margin-bottom: 20px;\">\n",
              "            <h4>Prediction Probabilities</h4>\n",
              "            <div>\n",
              "                <div>Simple</div>\n",
              "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
              "                    <div style=\"width: 60.418033599853516%; height: 100%; background-color: blue; border-radius: 5px;\"></div>\n",
              "                </div>\n",
              "                <p>Probability: 0.60</p>\n",
              "\n",
              "                <div>Complex</div>\n",
              "                <div style=\"width: 100%; height: 20px; background-color: #ddd; border-radius: 5px; margin: 5px 0;\">\n",
              "                    <div style=\"width: 39.581963419914246%; height: 100%; background-color: orange; border-radius: 5px;\"></div>\n",
              "                </div>\n",
              "                <p>Probability: 0.40</p>\n",
              "            </div>\n",
              "\n",
              "            <h4>Text with Highlighted Words</h4>\n",
              "            <p><span style='background-color: rgba(0, 0, 255, 0.0); padding: 2px;'>[CLS] </span><span style='background-color: rgba(255, 0, 0, 0.5102546498324181); padding: 2px;'>Pro </span><span style='background-color: rgba(255, 0, 0, 0.11840926439888029); padding: 2px;'>##vide </span><span style='background-color: rgba(255, 0, 0, 0.17755217849324084); padding: 2px;'>che </span><span style='background-color: rgba(255, 0, 0, 0.010299862673977749); padding: 2px;'>##ap </span><span style='background-color: rgba(255, 0, 0, 0.288883998486376); padding: 2px;'>care </span><span style='background-color: rgba(0, 0, 255, 0.33515353866524766); padding: 2px;'>that </span><span style='background-color: rgba(0, 0, 255, 0.17465679478099957); padding: 2px;'>helps </span><span style='background-color: rgba(0, 0, 255, 0.18513949142666403); padding: 2px;'>people </span><span style='background-color: rgba(255, 0, 0, 0.3174720567294473); padding: 2px;'>and </span><span style='background-color: rgba(0, 0, 255, 0.327756853293429); padding: 2px;'>their </span><span style='background-color: rgba(255, 0, 0, 0.09824684980528021); padding: 2px;'>care </span><span style='background-color: rgba(255, 0, 0, 0.2920208252724251); padding: 2px;'>##rs </span><span style='background-color: rgba(0, 0, 255, 0.30364009221051985); padding: 2px;'>feel </span><span style='background-color: rgba(255, 0, 0, 0.194828033175406); padding: 2px;'>safe </span><span style='background-color: rgba(0, 0, 255, 0.011320476006259931); padding: 2px;'>. </span><span style='background-color: rgba(0, 0, 255, 0.0); padding: 2px;'>[SEP] </span></p>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Word  Index  Attribution\n",
              "0     that      6     0.335154\n",
              "1    their     10     0.327757\n",
              "2     feel     13     0.303640\n",
              "3   people      8     0.185139\n",
              "4    helps      7     0.174657\n",
              "5        .     15     0.011320\n",
              "6    [SEP]     16     0.000000\n",
              "7    [CLS]      0     0.000000\n",
              "8     ##ap      4    -0.010300\n",
              "9     care     11    -0.098247\n",
              "10  ##vide      2    -0.118409"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8759dac-8e16-4f0c-bbdd-fe1996fa47ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Index</th>\n",
              "      <th>Attribution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>that</td>\n",
              "      <td>6</td>\n",
              "      <td>0.335154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>their</td>\n",
              "      <td>10</td>\n",
              "      <td>0.327757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>feel</td>\n",
              "      <td>13</td>\n",
              "      <td>0.303640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>people</td>\n",
              "      <td>8</td>\n",
              "      <td>0.185139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>helps</td>\n",
              "      <td>7</td>\n",
              "      <td>0.174657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>.</td>\n",
              "      <td>15</td>\n",
              "      <td>0.011320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[SEP]</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>##ap</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.010300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>care</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.098247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>##vide</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.118409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8759dac-8e16-4f0c-bbdd-fe1996fa47ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8759dac-8e16-4f0c-bbdd-fe1996fa47ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8759dac-8e16-4f0c-bbdd-fe1996fa47ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b9609f4-3382-4806-a060-9ee99b473b8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b9609f4-3382-4806-a060-9ee99b473b8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b9609f4-3382-4806-a060-9ee99b473b8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"analyze_and_display(sentence, label=1, tokenizer=tokenizer, model=model, device=device)\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \".\",\n          \"that\",\n          \"care\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 16,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          15,\n          6,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Attribution\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1698487962656031,\n        \"min\": -0.11840926439888029,\n        \"max\": 0.33515353866524766,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.09824684980528021,\n          0.327756853293429,\n          0.011320476006259931\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can process multiple sentences at once using the following approach:\n",
        "\n",
        "```python\n",
        "# List of sentences to analyze\n",
        "sentences = [\n",
        "    \"Provide financially sustainable care, giving security and stability to people and their carers.\",\n",
        "    \"Provide cheap care that helps people and their carers feel safe.\"\n",
        "]\n",
        "\n",
        "# Perform analysis for each sentence\n",
        "for sentence in sentences:\n",
        "    analyze_and_display(sentence, label=1, tokenizer=tokenizer, model=model, device=device)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Ai_n_KZmP127"
      }
    }
  ]
}